{
  "2": {
    "inputs": {
      "vae_name": "vae-ft-mse-840000-ema-pruned.safetensors"
    },
    "class_type": "VAELoader"
  },
  "3": {
    "inputs": {
      "text": "1girl, solo, cherry blossom, hanami, pink flower, white flower, spring season, wisteria, petals, flower, plum blossoms, outdoors, falling petals, black eyes, upper body, from left side, white kimono, purple hair",
      "clip": [
        "4",
        0
      ]
    },
    "class_type": "CLIPTextEncode"
  },
  "4": {
    "inputs": {
      "stop_at_clip_layer": -2,
      "clip": [
        "22",
        1
      ]
    },
    "class_type": "CLIPSetLastLayer"
  },
  "6": {
    "inputs": {
      "text": "embedding:easynegative",
      "clip": [
        "4",
        0
      ]
    },
    "class_type": "CLIPTextEncode"
  },
  "7": {
    "inputs": {
      "seed": 888888889,
      "steps": 20,
      "cfg": 8,
      "sampler_name": "euler",
      "scheduler": "normal",
      "denoise": 1,
      "model": [
        "20",
        0
      ],
      "positive": [
        "3",
        0
      ],
      "negative": [
        "6",
        0
      ],
      "latent_image": [
        "9",
        0
      ]
    },
    "class_type": "KSampler"
  },
  "9": {
    "inputs": {
      "width": 544,
      "height": 672,
      "batch_size": 48
    },
    "class_type": "EmptyLatentImage"
  },
  "13": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "scale_by": 1.5,
      "samples": [
        "7",
        0
      ]
    },
    "class_type": "LatentUpscaleBy"
  },
  "14": {
    "inputs": {
      "seed": 888888889,
      "steps": 5,
      "cfg": 8,
      "sampler_name": "euler",
      "scheduler": "normal",
      "denoise": 0.6499999999999997,
      "model": [
        "20",
        0
      ],
      "positive": [
        "3",
        0
      ],
      "negative": [
        "6",
        0
      ],
      "latent_image": [
        "13",
        0
      ]
    },
    "class_type": "KSampler"
  },
  "15": {
    "inputs": {
      "samples": [
        "14",
        0
      ],
      "vae": [
        "2",
        0
      ]
    },
    "class_type": "VAEDecode"
  },
  "20": {
    "inputs": {
      "model_name": "mm_sd_v15_v2.ckpt",
      "beta_schedule": "sqrt_linear (AnimateDiff)",
      "motion_scale": 1,
      "apply_v2_models_properly": true,
      "model": [
        "22",
        0
      ],
      "context_options": [
        "25",
        0
      ]
    },
    "class_type": "ADE_AnimateDiffLoaderWithContext"
  },
  "22": {
    "inputs": {
      "ckpt_name": "sd\\aniverse_v15Pruned.safetensors"
    },
    "class_type": "CheckpointLoaderSimple"
  },
  "25": {
    "inputs": {
      "context_length": 16,
      "context_stride": 1,
      "context_overlap": 4,
      "context_schedule": "uniform",
      "closed_loop": false
    },
    "class_type": "ADE_AnimateDiffUniformContextOptions"
  },
  "28": {
    "inputs": {
      "frame_rate": 8,
      "loop_count": 0,
      "filename_prefix": "23-12-12\\a",
      "format": "image/gif",
      "pingpong": false,
      "save_image": true,
      "crf": 20,
      "save_metadata": true,
      "audio_file": "",
      "videopreview": {
        "hidden": false,
        "paused": false,
        "params": {
          "filename": "a_00001.gif",
          "subfolder": "23-12-12",
          "type": "output",
          "format": "image/gif"
        }
      },
      "images": [
        "15",
        0
      ]
    },
    "class_type": "VHS_VideoCombine"
  }
}